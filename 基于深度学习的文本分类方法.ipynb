{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于深度学习的文本分类方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主要内容    \n",
    "* 前提介绍   \n",
    "* 深度学习简介:机器学习是学习样本与目标的函数关系,而深度学习相当于万能函数模拟器     \n",
    "* RNN, LSTM原理介绍:此类网络的结构决定了其适合学习此类内容(限定了函数空间范围)   \n",
    "* pytorch介绍   \n",
    "* torchtext、文本分类案例介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 前提介绍   \n",
    "行业偏离度模型的业务逻辑并不复杂, 利用征信公司名称预测征信行业, 并与实际表填行业相比较    \n",
    "这是一个典型的文本分类模型, 项目建设中使用了深度学习中的LSTM算法进行模型建设,    \n",
    "因此本次培训主要介绍LSTM算法相关的理论与实践方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（今天的这个培训主要是结合之前我做的一个“行业偏离度”模型进行的，由于这个模型在业务逻辑上很简单，就是利用征信公司名称预测征信行业, 并与实际表填行业相比较，没有太多值得介绍的，所以本次培训以介绍建模技术为主要内容，这个模型的建设主要使用了“基于深度学习的文本分类”，后续我会介绍相关的理论与实践方法，由于信息安全的原因，介绍实践的过程会利用公开数据源进行）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 深度学习简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo演示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RNN, LSTM原理简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humans don’t start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You don’t throw everything away and start thinking from scratch again. Your thoughts have persistence.\n",
    "\n",
    "Traditional neural networks can’t do this, and it seems like a major shortcoming. For example, imagine you want to classify what kind of event is happening at every point in a movie. It’s unclear how a traditional neural network could use its reasoning about previous events in the film to inform later ones.\n",
    "\n",
    "Recurrent neural networks address this issue. They are networks with loops in them, allowing information to persist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 RNN的计算图&展开后的计算图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p1.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p2.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 原版RNN存在长期依赖问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（然而理论中考虑了信息之间的相互依赖，并不代表实际使用中就能充分的利用这种依赖，实际上，原版的RNN难以保留长期依赖相关的信息，比如,如果利用RNN构建一个文本预测模型，那么）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "天空中有*云*    \n",
    "* 短期依赖, RNN可以正常识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p3.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我在法国长大, ............... 我可以说流利的*法语*    \n",
    "* 长期依赖, RNN难以识别(梯度长期传播会逐渐消失, 逻辑上类似 0.1^100 -> 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p4.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 LSTM: 同时考虑长、短期记忆的RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p5.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p6.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 通过增加线性运算部分，解决长期依赖问题    \n",
    "* C：cell state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p7.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 控制cell state信息的保留部分   \n",
    "* f: forget gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p8.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 控制cell state信息的新增部分    \n",
    "* i: input gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p9.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 生成新的cell state信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p10.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 以非线性方式生成h     \n",
    "* 与原有RNN结构类似, 不过是基于更新后的cell state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p11.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. pytorch介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 pytorch简介    \n",
    "* pytorch是什么: PyTorch是一个开源的Python机器学习库，基于Torch，最初由Facebook开发\n",
    "* 为什么使用pytorch: 动态计算图便于构建网络, 便于调试; 无需使用新增语法构建网络, 使用python标准语法即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/pytorch_joke.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 pytorch主要部分：  \n",
    "* tensor: 张量      \n",
    "    * 存储数据的基本变量(可以认为是多维数组)       \n",
    "           \n",
    "* autograd: 自动微分系统\n",
    "    * 深度学习的算法本质上是通过反向传播求导数，而autograd模块则实现了此功能。在Tensor上的所有操作，autograd都能为它们自动提供微分\n",
    "                  \n",
    "* nn: 常用神经网络的封装与函数\n",
    "    * Autograd实现了反向传播功能，但是直接用来写深度学习的代码在很多情况下还是稍显复杂，torch.nn是专门为神经网络设计的模块化接口。nn构建于Autograd之上，可用来定义和运行神经网络。\n",
    "    * nn.Module是nn中最重要的类，可把它看成是一个网络的封装，包含网络各层定义以及forward方法，利用nn.Module搭建网络,仅需实现初始化以及前向传播,而无需实现反向传播     \n",
    "                 \n",
    "* 其他: 优化器(torch.optim), 其它函数(nn.Functional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(下面简单介绍一下tensor和nn的操作方式)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Tensor例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azurite/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t # 注意包名是torch, 不是pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "几个Tensor操作的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.Tensor([[1,2],[3,4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9463, 0.9429, 0.7729],\n",
       "        [0.3115, 0.0486, 0.6924],\n",
       "        [0.3575, 0.8814, 0.3176],\n",
       "        [0.0646, 0.0846, 0.5125],\n",
       "        [0.7087, 0.8991, 0.7255]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用[0,1]均匀分布随机初始化二维数组\n",
    "x = t.rand(5, 3)  \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.ones(5) # 新建一个全1的Tensor\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor和 Numpy array可以相互转换\n",
    "b = a.numpy() # Tensor -> Numpy\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = t.from_numpy(a) # Numpy->Tensor\n",
    "print(a)\n",
    "print(b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 nn.Module例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 基于nn.Module定义网络时, 需要继承`nn.Module`, 并仅需实现其初始化方法(`__init__`, 告诉框架结构如何, 哪些是可训练参数), 以及前向传播方法(`forward`), 而无需实现反向传播方法(框架会利用`autograd`自动生成反向传播方法)       \n",
    "* 如果某一层(如ReLU)不具有可学习的参数，则既可以放在构造函数中，也可以不放，但建议不放在其中，而在forward中使用`nn.functional`代替。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多层感知机的网络结构如图4-1所示，它由两个全连接层组成，采用$sigmoid$函数作为激活函数，图中没有画出。\n",
    "![多层感知机](imgs/multi_perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是一个基础的前馈(feed-forward)网络: 接收输入，经过层层传递运算，得到输出。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        nn.Module.__init__(self)\n",
    "        # 此处使用了nn中预先定义好的线性层的结构, 第一个参数是输入维度,第二个是输出维度\n",
    "        self.layer1 = nn.Linear(in_features, hidden_features) \n",
    "        self.layer2 = nn.Linear(hidden_features, out_features)\n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = t.sigmoid(x)\n",
    "        return self.layer2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.weight torch.Size([4, 3])\n",
      "layer1.bias torch.Size([4])\n",
      "layer2.weight torch.Size([1, 4])\n",
      "layer2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(3, 4, 1) #生成如上图的3个input, 4个隐藏单元, 1个output的网络结构的实例\n",
    "for name, param in perceptron.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 一个简单的全流程训练例子   \n",
    "基于pytorch的模型的训练流程，主要由以下几部分组成    \n",
    "* 处理数据\n",
    "* 构建网络    \n",
    "* 确定损失函数和优化方法   \n",
    "* 开始进行优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理数据(生成dummy数据)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(size=100):\n",
    "    # 公式: y = 3x + 4 + ε\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for ix in range(size):\n",
    "        random_number = np.random.randint(100) / 100\n",
    "        inputs.append([random_number])\n",
    "        outputs.append([3 * random_number + 4 + np.random.normal() / 10])\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc2a04d51d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2a0749828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 来看看产生的x-y分布\n",
    "test_x, test_y = generate_dataset()\n",
    "plt.scatter(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LR, self).__init__()\n",
    "        self.fc = nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "model = LR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确定损失函数和优化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define critereon - loss function\n",
    "critereon = nn.MSELoss()\n",
    "# define optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始进行优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 : Loss 0.003618097398430109\n",
      "Epoch 9 : Loss 0.007106496952474117\n",
      "Epoch 14 : Loss 0.009541959501802921\n",
      "Epoch 19 : Loss 0.011044839397072792\n",
      "Epoch 24 : Loss 0.011924119666218758\n",
      "Epoch 29 : Loss 0.012425823137164116\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = generate_dataset(100)\n",
    "nb_epochs = 30\n",
    "for epoch in range(nb_epochs):\n",
    "    epoch_loss = 0\n",
    "    for ix, x in enumerate(inputs):\n",
    "        # here x is the input. i.e. the input value of x\n",
    "        # and y_train[ix] is the output. i.e. y = f(x) = 3x + 4\n",
    "        y_pred = model(t.Tensor(x))\n",
    "        \n",
    "        loss = critereon(y_pred, t.Tensor(labels[ix]))\n",
    "        \n",
    "        epoch_loss = loss.data.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 5 == 4:\n",
    "        print(\"Epoch {} : Loss {}\".format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简要测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2a075de10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#x_test, y_test = get_fake_data(batch_size=40)\n",
    "label_pred = model(t.Tensor(inputs))\n",
    "plt.scatter(inputs, labels) # predicted\n",
    "\n",
    "plt.plot(inputs, label_pred.detach().numpy(), 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. torchtext、文本分类案例介绍    \n",
    "基于上述的理论与实践知识，我们可以开始建设实际的文本分类模型了，我们会基于`Toxic Comment Classification`这个例子进行介绍    \n",
    "由于实际工程任务中，预处理相关操作较为繁琐，在这里我也会同步介绍一个用于文本预处理的torchtext包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Toxic Comment Classification`： “有毒”评论分类   \n",
    "数据选取了Wikipedia’s talk page edits下的评论，分别被标注了toxic、severe_toxic、obscene、threat、insult以及identity_hate这6类标签，目的是建立模型以判断某条评论是否出现以上行为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/torchtext_routine.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 查看数据基本情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv  train.csv  valid.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = pd.read_csv(\"data/train.csv\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp['comment_text'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 声明 Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何对文本数据进行预处理并转换为数字，是利用Field实现的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data import Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们想把comment_text转化为小写，并按空格进行token化，所以如下选择Field参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda x: x.split()\n",
    "TEXT = Field(sequential=True, tokenize=tokenize, lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于此数据集中标签已进行基础处理，所以对标签的处理就更为简单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 生成数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于数据源是csv格式的，我们使用TabularDataset读取数据 (目前TabularDataset可以处理csv, tsv, 以及json文件)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于训练、验证数据，我们需要处理标签，传入参数的顺序必须与数据集中的顺序一直（不需要的数据可以传个None）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.45 ms, sys: 374 µs, total: 2.83 ms\n",
      "Wall time: 4.83 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tv_datafields = [(\"id\", None), \n",
    "                 (\"comment_text\", TEXT), (\"toxic\", LABEL),\n",
    "                 (\"severe_toxic\", LABEL), (\"threat\", LABEL),\n",
    "                 (\"obscene\", LABEL), (\"insult\", LABEL),\n",
    "                 (\"identity_hate\", LABEL)]\n",
    "\n",
    "trn, vld = TabularDataset.splits(\n",
    "        path=\"data\", # 数据都在data文件夹下\n",
    "        train='train.csv', validation=\"valid.csv\",\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=tv_datafields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集中没有任何的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 ms, sys: 319 µs, total: 2.42 ms\n",
      "Wall time: 4.16 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tst_datafields = [(\"id\", None), \n",
    "                 (\"comment_text\", TEXT)\n",
    "]\n",
    "\n",
    "tst = TabularDataset(\n",
    "        path=\"data/test.csv\", # the file path\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=tst_datafields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding(词嵌入，用一个低维向量表示词) 之类的后续处理，需要先将文本转化为数字，因此我们需要基于文本构建词库，构建方法如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.4 ms, sys: 212 µs, total: 1.61 ms\n",
      "Wall time: 1.61 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TEXT.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "词库如下， vocab.freqs是一个collections.Counter对象，所以我们可以看一下最常出现的几个词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 78),\n",
       " ('to', 41),\n",
       " ('you', 33),\n",
       " ('of', 30),\n",
       " ('and', 26),\n",
       " ('a', 26),\n",
       " ('is', 24),\n",
       " ('that', 22),\n",
       " ('i', 20),\n",
       " ('if', 19)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们稍微看一下数据集被转换成什么样子，数据集可以像list一样使用索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explanation', 'why', 'the']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0].comment_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对train和valid数据集，我们使用一种特殊的iterator，叫**BucketIterator**    \n",
    "当我们使用神经网络进行训练时，每一个batch的长度应该是一样的，长度不足的会补0，过长的会切断   \n",
    "e.g.\n",
    "\\[ \n",
    "\\[3, 15, 2, 7\\],\n",
    "\\[4, 1\\], \n",
    "\\[5, 5, 6, 8, 1\\] \n",
    "\\] -> \\[ \n",
    "\\[3, 15, 2, 7, **0**\\],\n",
    "\\[4, 1, **0**, **0**, **0**\\], \n",
    "\\[5, 5, 6, 8, 1\\] \n",
    "\\]    \n",
    "如果数据长度相差太多，处理过程就会比较费时    \n",
    "BucketIterator会将相似长度的数据放到一起处理，降低耗时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "train_iter, val_iter = BucketIterator.splits(\n",
    "        (trn, vld), # we pass in the datasets we want the iterator to draw data from\n",
    "        batch_sizes=(64, 64),\n",
    "        device=-1, # if you want to use the GPU, specify the GPU number here\n",
    "        sort_key=lambda x: len(x.comment_text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "        sort_within_batch=False,\n",
    "        repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test部分不需要重排序，所以使用标准的Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "test_iter = Iterator(tst, batch_size=64, device=-1, sort=False, sort_within_batch=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 封装迭代器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了便于使用，我们将把batch转换为形式为（x，y）的元组，其中x是自变量（模型的输入），y是因变量（标签数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_vars):\n",
    "        self.dl, self.x_var, self.y_vars = dl, x_var, y_vars # we pass in the list of attributes for x and y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            \n",
    "            if self.y_vars is not None: # we will concatenate y into a single tensor\n",
    "                y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y_vars], dim=1).float()\n",
    "            else:\n",
    "                y = torch.zeros((1))\n",
    "\n",
    "            yield (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用上面这个类来封装BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BatchWrapper(train_iter, \"comment_text\", [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\n",
    "valid_dl = BatchWrapper(val_iter, \"comment_text\", [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\n",
    "test_dl = BatchWrapper(test_iter, \"comment_text\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面就是每一组我们实际用来训练的数据、标签在经过上述预处理后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[660,  63,  15,  ..., 354,  15,  44],\n",
       "         [ 11,   4,  46,  ...,  63,  29, 739],\n",
       "         [  2, 664,  10,  ...,   4,  21,   3],\n",
       "         ...,\n",
       "         [  1,   1,   1,  ...,   1,  84,   1],\n",
       "         [  1,   1,   1,  ...,   1, 118,   1],\n",
       "         [  1,   1,   1,  ...,   1,  15,   1]]),\n",
       " tensor([[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立并训练文本分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处利用我们上面提到的LSTM建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Embedding in module torch.nn.modules.sparse:\n",
      "\n",
      "class Embedding(torch.nn.modules.module.Module)\n",
      " |  A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
      " |  \n",
      " |  This module is often used to store word embeddings and retrieve them using indices.\n",
      " |  The input to the module is a list of indices, and the output is the corresponding\n",
      " |  word embeddings.\n",
      " |  \n",
      " |  Args:\n",
      " |      num_embeddings (int): size of the dictionary of embeddings\n",
      " |      embedding_dim (int): the size of each embedding vector\n",
      " |      padding_idx (int, optional): If given, pads the output with the embedding vector at :attr:`padding_idx`\n",
      " |                                       (initialized to zeros) whenever it encounters the index.\n",
      " |      max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n",
      " |                                  is renormalized to have norm :attr:`max_norm`.\n",
      " |      norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n",
      " |      scale_grad_by_freq (boolean, optional): If given, this will scale gradients by the inverse of frequency of\n",
      " |                                              the words in the mini-batch. Default ``False``.\n",
      " |      sparse (bool, optional): If ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor.\n",
      " |                               See Notes for more details regarding sparse gradients.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight (Tensor): the learnable weights of the module of shape (num_embeddings, embedding_dim)\n",
      " |                       initialized from :math:`\\mathcal{N}(0, 1)`\n",
      " |  \n",
      " |  Shape:\n",
      " |  \n",
      " |      - Input: LongTensor of arbitrary shape containing the indices to extract\n",
      " |      - Output: `(*, embedding_dim)`, where `*` is the input shape\n",
      " |  \n",
      " |  .. note::\n",
      " |      Keep in mind that only a limited number of optimizers support\n",
      " |      sparse gradients: currently it's :class:`optim.SGD` (`CUDA` and `CPU`),\n",
      " |      :class:`optim.SparseAdam` (`CUDA` and `CPU`) and :class:`optim.Adagrad` (`CPU`)\n",
      " |  \n",
      " |  .. note::\n",
      " |      With :attr:`padding_idx` set, the embedding vector at\n",
      " |      :attr:`padding_idx` is initialized to all zeros. However, note that this\n",
      " |      vector can be modified afterwards, e.g., using a customized\n",
      " |      initialization method, and thus changing the vector used to pad the\n",
      " |      output. The gradient for this vector from :class:`~torch.nn.Embedding`\n",
      " |      is always zero.\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> # an Embedding module containing 10 tensors of size 3\n",
      " |      >>> embedding = nn.Embedding(10, 3)\n",
      " |      >>> # a batch of 2 samples of 4 indices each\n",
      " |      >>> input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
      " |      >>> embedding(input)\n",
      " |      tensor([[[-0.0251, -1.6902,  0.7172],\n",
      " |               [-0.6431,  0.0748,  0.6969],\n",
      " |               [ 1.4970,  1.3448, -0.9685],\n",
      " |               [-0.3677, -2.7265, -0.1685]],\n",
      " |  \n",
      " |              [[ 1.4970,  1.3448, -0.9685],\n",
      " |               [ 0.4362, -0.4004,  0.9400],\n",
      " |               [-0.6431,  0.0748,  0.6969],\n",
      " |               [ 0.9124, -2.3616,  1.1151]]])\n",
      " |  \n",
      " |  \n",
      " |      >>> # example with padding_idx\n",
      " |      >>> embedding = nn.Embedding(10, 3, padding_idx=0)\n",
      " |      >>> input = torch.LongTensor([[0,2,0,5]])\n",
      " |      >>> embedding(input)\n",
      " |      tensor([[[ 0.0000,  0.0000,  0.0000],\n",
      " |               [ 0.1535, -2.0309,  0.9315],\n",
      " |               [ 0.0000,  0.0000,  0.0000],\n",
      " |               [-0.1655,  0.9897,  0.0635]]])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Embedding\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should reimplement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  forward(self, input)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  reset_parameters(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_pretrained(embeddings, freeze=True, sparse=False) from builtins.type\n",
      " |      Creates Embedding instance from given 2-dimensional FloatTensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          embeddings (Tensor): FloatTensor containing weights for the Embedding.\n",
      " |              First dimension is being passed to Embedding as 'num_embeddings', second as 'embedding_dim'.\n",
      " |          freeze (boolean, optional): If ``True``, the tensor does not get updated in the learning process.\n",
      " |              Equivalent to ``embedding.weight.requires_grad = False``. Default: ``True``\n",
      " |          sparse (bool, optional): if ``True``, gradient w.r.t. weight matrix will be a sparse tensor.\n",
      " |              See Notes for more details regarding sparse gradients.\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> # FloatTensor containing pretrained weights\n",
      " |          >>> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\n",
      " |          >>> embedding = nn.Embedding.from_pretrained(weight)\n",
      " |          >>> # Get embeddings for index 1\n",
      " |          >>> input = torch.LongTensor([1])\n",
      " |          >>> embedding(input)\n",
      " |          tensor([[ 4.0000,  5.1000,  6.3000]])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __constants__ = ['num_embeddings', 'embedding_dim', 'padding_idx', 'ma...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__(self, *input, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      __dir__() -> list\n",
      " |      default dir() implementation\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name, module)\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          parameter (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`torch-nn-init`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> def init_weights(m):\n",
      " |                  print(m)\n",
      " |                  if type(m) == nn.Linear:\n",
      " |                      m.weight.data.fill_(1.0)\n",
      " |                      print(m.weight)\n",
      " |      \n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  buffers(self, recurse=True)\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf.data), buf.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self)\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self, device=None)\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self)\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self)\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |  \n",
      " |  float(self)\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self)\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict, strict=True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |  \n",
      " |  modules(self)\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          )\n",
      " |          1 -> Linear (2 -> 2)\n",
      " |  \n",
      " |  named_buffers(self, prefix='', recurse=True)\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self)\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo=None, prefix='')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear (2 -> 2))\n",
      " |  \n",
      " |  named_parameters(self, prefix='', recurse=True)\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse=True)\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param.data), param.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook)\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |      \n",
      " |      .. warning ::\n",
      " |      \n",
      " |          The current implementation will not have the presented behavior\n",
      " |          for complex :class:`Module` that perform many operations.\n",
      " |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n",
      " |          contain the gradients for a subset of the inputs and outputs.\n",
      " |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n",
      " |          directly on a specific input or output to get the required gradients.\n",
      " |  \n",
      " |  register_buffer(self, name, tensor)\n",
      " |      Adds a persistent buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the persistent state.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None\n",
      " |      \n",
      " |      The hook should not modify the input or output.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook)\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None\n",
      " |      \n",
      " |      The hook should not modify the input.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name, param)\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          parameter (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  share_memory(self)\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point desired :attr:`dtype` s. In addition, this method will\n",
      " |      only cast the floating point parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self, mode=True)\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self, dst_type)\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self)\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBiLSTMBaseline(nn.Module):\n",
    "    def __init__(self, hidden_dim, emb_dim=300, recurrent_dropout=0.1, num_linear=1):\n",
    "        super().__init__() # don't forget to call this!\n",
    "        self.embedding = nn.Embedding(len(TEXT.vocab), emb_dim)\n",
    "        self.encoder = nn.LSTM(emb_dim, hidden_dim, num_layers=1, dropout=recurrent_dropout)\n",
    "        self.linear_layers = []\n",
    "        for _ in range(num_linear - 1):\n",
    "            self.linear_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        # 含可优化参数的层，需要使用nn.ModuleList, 这样其中可优化参数才能存到构造函数中的正确位置\n",
    "        self.linear_layers = nn.ModuleList(self.linear_layers)\n",
    "        self.predictor = nn.Linear(hidden_dim, 6)\n",
    "    \n",
    "    def forward(self, seq):\n",
    "        hdn, _ = self.encoder(self.embedding(seq))\n",
    "        feature = hdn[-1, :, :]\n",
    "        for layer in self.linear_layers:\n",
    "            feature = layer(feature)\n",
    "        preds = self.predictor(feature)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azurite/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleBiLSTMBaseline(\n",
       "  (embedding): Embedding(784, 100)\n",
       "  (encoder): LSTM(100, 500, dropout=0.1)\n",
       "  (linear_layers): ModuleList()\n",
       "  (predictor): Linear(in_features=500, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_sz = 100\n",
    "nh = 500\n",
    "nl = 3\n",
    "model = SimpleBiLSTMBaseline(nh, emb_dim=em_sz); model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using a GPU, remember to call model.cuda() to move your model to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleBiLSTMBaseline(\n",
       "  (embedding): Embedding(784, 100)\n",
       "  (encoder): LSTM(100, 500, dropout=0.1)\n",
       "  (linear_layers): ModuleList()\n",
       "  (predictor): Linear(in_features=500, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 13.3428, Validation Loss: 2.0577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 3.5562, Validation Loss: 1.8832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 3.0052, Validation Loss: 2.0320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 3.4152, Validation Loss: 1.9068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training Loss: 2.8913, Validation Loss: 2.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Training Loss: 3.0458, Validation Loss: 2.1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Training Loss: 3.0925, Validation Loss: 2.0956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Training Loss: 3.0174, Validation Loss: 2.0679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Training Loss: 2.9133, Validation Loss: 2.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: 2.8691, Validation Loss: 2.1290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Training Loss: 2.9281, Validation Loss: 2.1762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Training Loss: 2.9727, Validation Loss: 2.1732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Training Loss: 2.9180, Validation Loss: 2.1638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Training Loss: 2.8657, Validation Loss: 2.1762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Training Loss: 2.8740, Validation Loss: 2.2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Training Loss: 2.9080, Validation Loss: 2.2206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Training Loss: 2.9218, Validation Loss: 2.2304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Training Loss: 2.9048, Validation Loss: 2.2329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Training Loss: 2.8753, Validation Loss: 2.2362\n",
      "Epoch: 20, Training Loss: 2.8594, Validation Loss: 2.2470\n",
      "CPU times: user 3.13 s, sys: 1.35 s, total: 4.48 s\n",
      "Wall time: 4.43 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() # turn on training mode\n",
    "    for x, y in tqdm.tqdm(train_dl): # thanks to our wrapper, we can intuitively iterate over our data!\n",
    "        opt.zero_grad()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        preds = model(x)\n",
    "        loss = loss_func(preds, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        running_loss += loss.data.item() * x.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(trn)\n",
    "    \n",
    "    # calculate the validation loss for this epoch\n",
    "    val_loss = 0.0\n",
    "    model.eval() # turn on evaluation mode\n",
    "    for x, y in valid_dl:\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        preds = model(x)\n",
    "        loss = loss_func(preds, y)\n",
    "        val_loss += loss.data.item() * x.size(0)\n",
    "\n",
    "    val_loss /= len(vld)\n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, epoch_loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.BatchWrapper at 0x110269c18>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.35it/s]\n"
     ]
    }
   ],
   "source": [
    "test_preds = []\n",
    "for x, y in tqdm.tqdm(test_dl):\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    preds = model(x)\n",
    "    # if you're data is on the GPU, you need to move the data back to the cpu\n",
    "    preds = preds.data.cpu().numpy()\n",
    "    # preds = preds.data.numpy()\n",
    "    # the actual outputs of the model are logits, so we need to pass these values to the sigmoid function\n",
    "    preds = 1 / (1 + np.exp(-preds))\n",
    "    test_preds.append(preds)\n",
    "#test_preds = np.hstack(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/test.csv\")\n",
    "for i, col in enumerate([\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]):\n",
    "    df[col] = test_preds[:, i]\n",
    "\n",
    "# if you want to write the submission file to disk, uncomment and run the below code\n",
    "# df.drop(\"comment_text\", axis=1).to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>0.134493</td>\n",
       "      <td>0.040768</td>\n",
       "      <td>1.069173e-07</td>\n",
       "      <td>0.039633</td>\n",
       "      <td>0.041238</td>\n",
       "      <td>8.983147e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>0.134493</td>\n",
       "      <td>0.040768</td>\n",
       "      <td>1.069173e-07</td>\n",
       "      <td>0.039633</td>\n",
       "      <td>0.041238</td>\n",
       "      <td>8.983147e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>0.134493</td>\n",
       "      <td>0.040768</td>\n",
       "      <td>1.069173e-07</td>\n",
       "      <td>0.039633</td>\n",
       "      <td>0.041238</td>\n",
       "      <td>8.983147e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>0.134493</td>\n",
       "      <td>0.040768</td>\n",
       "      <td>1.069173e-07</td>\n",
       "      <td>0.039633</td>\n",
       "      <td>0.041238</td>\n",
       "      <td>8.983147e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>0.134493</td>\n",
       "      <td>0.040768</td>\n",
       "      <td>1.069173e-07</td>\n",
       "      <td>0.039633</td>\n",
       "      <td>0.041238</td>\n",
       "      <td>8.983147e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "      toxic  severe_toxic       obscene    threat    insult  identity_hate  \n",
       "0  0.134493      0.040768  1.069173e-07  0.039633  0.041238   8.983147e-08  \n",
       "1  0.134493      0.040768  1.069173e-07  0.039633  0.041238   8.983147e-08  \n",
       "2  0.134493      0.040768  1.069173e-07  0.039633  0.041238   8.983147e-08  \n",
       "3  0.134493      0.040768  1.069173e-07  0.039633  0.041238   8.983147e-08  \n",
       "4  0.134493      0.040768  1.069173e-07  0.039633  0.041238   8.983147e-08  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:   \n",
    "  * http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/\n",
    "  * http://colah.github.io/posts/2015-08-Understanding-LSTMs/   \n",
    "  * https://github.com/chenyuntc/pytorch-book   \n",
    "  * https://medium.com/@ally_20818/pytorch-101-linear-regression-with-pytorch-d2d22291c37d \n",
    "  * `Toxic Comment Classification`: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge        \n",
    "  * https://zhuanlan.zhihu.com/p/37223078    \n",
    "  * https://github.com/keitakurita/practical-torchtext"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
