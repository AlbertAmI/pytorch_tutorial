{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于深度学习的文本分类方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主要内容    \n",
    "* 前提介绍   \n",
    "* 深度学习简介\n",
    "* RNN, LSTM原理介绍\n",
    "* pytorch介绍   \n",
    "* torchtext、文本分类案例介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 前提介绍   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（今天的这个培训主要是结合之前我做的一个“行业偏离度”模型进行的，由于这个模型在业务逻辑上很简单，就是利用征信公司名称预测征信行业, 并与实际表填行业相比较，没有太多值得介绍的，所以本次培训以介绍建模技术为主要内容，这个模型的建设主要使用了“基于深度学习的文本分类”，后续我会介绍相关的理论与实践方法，由于信息安全的原因，介绍实践的过程会利用公开数据源进行）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 深度学习简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 深度神经网络结构简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/network_example.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/simple_perceptron.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个基础的神经网络主要由输入层、隐藏层以及输出层组成(如图1所示)，每一个黄色圆点叫做一个神经元，每两个神经元由一系列线性&非线性变换链接   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 为什么深度学习是有效的？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经元之间的非线性变换使模型具有表示复杂非线性关系的能力，而这正是建模过程中需要的(因为，机器学习就是学习数据与目标之间的某种复杂函数关系)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo演示(对深度神经网络非线性的一个直观展示)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RNN, LSTM原理简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们来介绍一下适用于序列类（句子/文章、语音等）学习的网络RNN    \n",
    "\n",
    "当我们阅读文章时，对当前词句的理解是基于前文进行的，所以我们的阅读、思考过程具有“持久性”，但传统的神经网络结构却无法表示这一点，`RNN(Recurrent neural network)`的提出解决了这一问题，这种网络结构中含有循环，因此可以允许信息“持久”保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 RNN的计算图&展开后的计算图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p1.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p2.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 原版RNN存在长期依赖问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "理论中考虑了信息之间的相互依赖，并不代表实际使用中就能充分的利用这种依赖，实际上，原版的RNN难以保留长期依赖相关的信息，比如,如果利用RNN构建一个文本预测模型，那么不同长度的文本其实会有不同的表现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "天空中有*云*    \n",
    "* 短期依赖, RNN可以正常识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p3.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我在法国长大, ............... 我可以说流利的*法语*    \n",
    "* 长期依赖, RNN难以识别(梯度长期传播会逐渐消失, 逻辑上类似 0.1^100 -> 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p4.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 LSTM: 同时考虑长、短期记忆的RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p5.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p6.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 通过增加线性运算部分，解决长期依赖问题    \n",
    "* C：cell state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p7.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 控制cell state信息的保留部分   \n",
    "* f: forget gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p8.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 控制cell state信息的新增部分    \n",
    "* i: input gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p9.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 生成新的cell state信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p10.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 以非线性方式生成h     \n",
    "* 与原有RNN结构类似, 不过是基于更新后的cell state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/p11.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. pytorch介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 pytorch简介    \n",
    "* pytorch是什么: PyTorch是一个开源的Python机器学习库，基于Torch，最初由Facebook开发\n",
    "* 为什么使用pytorch: 动态计算图便于构建网络, 便于调试; 无需使用新增语法构建网络, 使用python标准语法即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/pytorch_joke.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 pytorch主要部分：  \n",
    "* tensor: 张量      \n",
    "    * 存储数据的基本变量(可以认为是多维数组)       \n",
    "           \n",
    "* autograd: 自动微分系统\n",
    "    * 深度学习的算法本质上是通过反向传播求导数，而autograd模块则实现了此功能。在Tensor上的所有操作，autograd都能为它们自动提供微分\n",
    "                  \n",
    "* nn: 常用神经网络的封装与函数\n",
    "    * Autograd实现了反向传播功能，但是直接用来写深度学习的代码在很多情况下还是稍显复杂，torch.nn是专门为神经网络设计的模块化接口。nn构建于Autograd之上，可用来定义和运行神经网络。\n",
    "    * nn.Module是nn中最重要的类，可把它看成是一个网络的封装，包含网络各层定义以及forward方法，利用nn.Module搭建网络,仅需实现初始化以及前向传播,而无需实现反向传播     \n",
    "                 \n",
    "* 其他: 优化器(torch.optim), 其它函数(nn.Functional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(下面简单介绍一下tensor和nn的操作方式)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Tensor例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azurite/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t # 注意包名是torch, 不是pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "几个Tensor操作的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.Tensor([[1,2],[3,4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0010, 0.2716, 0.0785],\n",
       "        [0.1225, 0.1551, 0.7609],\n",
       "        [0.0991, 0.8552, 0.1813],\n",
       "        [0.4214, 0.5452, 0.7405],\n",
       "        [0.8041, 0.1878, 0.9650]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用[0,1]均匀分布随机初始化二维数组\n",
    "x = t.rand(5, 3)  \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.ones(5) # 新建一个全1的Tensor\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor和 Numpy array可以相互转换\n",
    "b = a.numpy() # Tensor -> Numpy\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = t.from_numpy(a) # Numpy->Tensor\n",
    "print(a)\n",
    "print(b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 nn.Module例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 基于nn.Module定义网络时, 需要继承`nn.Module`, 并仅需实现其初始化方法(`__init__`, 告诉框架结构如何, 哪些是可训练参数), 以及前向传播方法(`forward`), 而无需实现反向传播方法(框架会利用`autograd`自动生成反向传播方法)       \n",
    "* 如果某一层(如ReLU)不具有可学习的参数，则既可以放在构造函数中，也可以不放，但建议不放在其中，而在forward中使用`nn.functional`代替。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多层感知机的网络结构如图4-1所示，它由两个全连接层组成，采用$sigmoid$函数作为激活函数，图中没有画出。\n",
    "![多层感知机](imgs/multi_perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是一个基础的前馈(feed-forward)网络: 接收输入，经过层层传递运算，得到输出。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        nn.Module.__init__(self)\n",
    "        # 此处使用了nn中预先定义好的线性层的结构, 第一个参数是输入维度,第二个是输出维度\n",
    "        self.layer1 = nn.Linear(in_features, hidden_features) \n",
    "        self.layer2 = nn.Linear(hidden_features, out_features)\n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = t.sigmoid(x)\n",
    "        return self.layer2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.weight torch.Size([4, 3])\n",
      "layer1.bias torch.Size([4])\n",
      "layer2.weight torch.Size([1, 4])\n",
      "layer2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(3, 4, 1) #生成如上图的3个input, 4个隐藏单元, 1个output的网络结构的实例\n",
    "for name, param in perceptron.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 一个简单的全流程训练例子   \n",
    "基于pytorch的模型的训练流程，主要由以下几部分组成    \n",
    "* 处理数据\n",
    "* 构建网络    \n",
    "* 确定损失函数和优化方法   \n",
    "* 开始进行优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理数据(生成dummy数据)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(size=100):\n",
    "    # 公式: y = 3x + 4 + ε\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for ix in range(size):\n",
    "        random_number = np.random.randint(100) / 100\n",
    "        inputs.append([random_number])\n",
    "        outputs.append([3 * random_number + 4 + np.random.normal() / 10])\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb560a178d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHRpJREFUeJzt3X+Q3XV97/HnezdHXRxhqawtLImBe2moyIXAFnAy45VwayrSkBGsMGW8tM7NxB9UcJrOMrVqKb3m3kyvYu3IjfaXV8UU1DQWFPUGRidtcu/GLKQK6UQEkw2V1bKozarL5t0/zjnL2XO+3+/5nHO+58f3+309Znay53u+e87ny4b3+eT9fX/eH3N3REQkX4b6PQAREUmfgruISA4puIuI5JCCu4hIDim4i4jkkIK7iEgOKbiLiOSQgruISA4puIuI5NCKfr3xGWec4atXr+7X24uIZNKBAwd+4O5jzc7rW3BfvXo1U1NT/Xp7EZFMMrOnQs5TWkZEJIcU3EVEckjBXUQkhxTcRURySMFdRCSHFNxFRHKob6WQIiJZt+vgDNsfPMzxuXnOGh1h64Y1bFo73u9hAQruIiJt2XVwhts/f4j5hUUAZubmuf3zhwAGIsArLSMi0obtDx5eCuxV8wuLbH/wcJ9GtFzT4G5ma8xsuubrR2Z2a905ZmYfMbMjZvaomV3SvSGLiPTf8bn5lo73WtO0jLsfBi4GMLNhYAb4Qt1pbwDOq3xdDnys8qeISC6dNTrCTEQgP2t0pA+jadRqWuYq4DvuXt/b4Frgk162Dxg1szNTGaGIyADaumENI6XhZceMcu593bY97Do405+BVbQa3G8A7ok4Pg4crXl8rHJMRCSXNq0d54NvupDxykzdAK88V7252s8AHxzczexFwEbg3qinI455w0lmm81sysymZmdnw0cpIjKANq0dZ+/kesZHRxoCXr9vrrYyc38D8E13/37Ec8eAlTWPzwaO15/k7jvcfcLdJ8bGmrYjFhHJhEG8udpKcL+R6JQMwG7grZWqmSuA59z96Y5HJyKSAXE3Uft5czUouJvZKcCvAZ+vObbFzLZUHj4APAEcAT4OvCPlcYqIDKwrz4/ORMQd74WgFarufgJ4ed2xu2u+d+Cd6Q5NRCQbHno8+h7iQ4/P9q1FgdoPiIh0KC63Xq2a6UeLArUfEBFpYtfBGdZt28M5k/dH1rDH5daHzfrWokDBXUQkQbVB2MzcPE50DXvUgqaR0jCL3lARDvSmikbBXUQkQUiDsNoFTQaMj44sW+BUrxdVNMq5i4gkCK1h37R2PDKPXptzh/KMfuuGNekOMoJm7iIiCTqpYY+b0ataRkSkz7ZuWNPR7DtuRt9tmrmLiCSon32ffkqJF68Y4rad0wPR/TGOZu4iIk1UZ99JW+sBA7WfqoK7iEiE2pWlp42UMINnTyw0nDe/sMgHdn+Lnz1/cqD2U1VaRkSkTn1t+9z8QmRgr5qbXxi4/VQ1cxeRworr+xJV296Ofrb8VXAXkUKKyp/ftnOaW3dOt/Q6I6VhXlIaipzZ97Plr4K7iORSs26MUbPz6GYB8cYrrwv9W6wUR8FdRHInqaqlGuA7SZmUhoztb76o4WapqmVERLooqR9MNeCeNTrCTLsBPmLX6H4tVoqjahkRyZ2kfjDV9r0hgX18dCSy+dfCove1EiaEgruI5E7cjczRU0psvfeRoMBezZkP4ubXIRTcRSR34vqr/3RhkYWTzW+b1jb4GsTNr0Mo5y4imZZUFVN/PKTMcXx0hL2T65ced9o4rF8U3EUks5pVxVSDfPUDoJmooB33QTFIN0+jKLiLSGaFVMXUfwDEGU8I2oNWCRNCwV1EMiEq/RJys7NZK4HSsLH9+saa9axTcBeRvmu2mjQu/XLaSIm5+eRl/0lVLcNmvOVXV+YusENgtYyZjZrZfWb2uJk9ZmavqXv+dWb2nJlNV77e153hikje1HdgrAbu2k0w4tIvZkRWxdTmzZOqWhbd+dyBmYHdcKMToaWQdwFfdvfzgYuAxyLO+Ya7X1z5uiO1EYpIriXlzaviZt9zJxa47tJxhq28ZHTYjOsuXZ4fjyqLTHqvvGga3M3sVOC1wF8AuPvP3X2u2wMTkWIIyZvHzb4d+PS+77Ho5dr1qJl47TZ5rY4hy0Jm7ucCs8BfmdlBM/uEmb004rzXmNkjZvYlM7sg6oXMbLOZTZnZ1OzsbCfjFpGcCFkklDT7rl+SFDUT37R2nL2T62MD/KAvSGpHSHBfAVwCfMzd1wL/BkzWnfNN4JXufhHwZ8CuqBdy9x3uPuHuE2NjYx0MW0TyIm416dYNa5b6wNy2cxpwhiIadkWJm4knvVfehAT3Y8Axd99feXwf5WC/xN1/5O4/qXz/AFAyszNSHamI5FJt2sR4Yek/sOxG6/zCSQI6BwDxM/G498pjtUzTUkh3/xczO2pma9z9MHAV8O3ac8zsl4Dvu7ub2WWUPzR+2JURi0juRC0SWrdtT1tb3TWbiWdxQVI7QuvcbwE+bWYvAp4AftvMtgC4+93A9cDbzex5YB64wd1b3dRERGRJK73WjXLuPWmVadEEBXd3nwYm6g7fXfP8R4GPpjguESm4YbOlKpgkCujRtEJVRAZSs8A+UhrObb48DernLiIDKakuPWqxkiyn4C4iAymptj3PbQPSorSMiAyU2iZip42UeElpiGdPNDYHq2/tK8spuItI19QHarNyP5i4DS/quz/OzS8k9oXJY9uAtCi4i0hXRAXqqvodk6ofAlHlj/MLi7GVM3lsG5AWBXcR6Ypmm2TU9oBptlPSojsjpeHM7WPaT7qhKiINqj1dzpm8n3Xb9rR14zIkZXJ8br7phwC80CagCG0D0qKZu4gs02zT6VBnjY40XWV61uhI0w+B6gy9KG0D0qKZu4gsE7J5Rohmm2RUg3ZS3lwz9PZp5i4iy4RsnhGiGpBDqmXqc+5afdo5BXcRWSYundJOZUpIKqX+QyCuTFJao+AuIsts3bAmcibdzcoU5dPTp+AuUmC1i4zqZ8yaSWebgrtIAUQFcSCxKkbBPNsU3EVyLq608cUrhmKrYhTYs0/BXSSHamfqQxFL9+cXFmMXDqlfSz4ouIvkTP1MPWQ3o1rq15IPCu4iOROynB/g9FNK/HThZGRVTNKNVskGBXeRnAlJq4yUhnn/b1wANFbFQPKN1ij6MBg8Cu4iORO3CGnYjJPuDcG3Pgiv27Yn8kbrrTun2f7g4YbAnVYvGkmXgrtIzsQtQgpdzp80848K3Em9aBTc+0eNw0RyZtPa8bba41bb/Da7/VrfRCytXjSSrqCZu5mNAp8AXg048Dvu/o81zxtwF3A1cAK42d2/mf5wRSREq4uQ6lMrzdQG7jR70Uh6QmfudwFfdvfzgYuAx+qefwNwXuVrM/Cx1EYoIl0XWmFTVRu4o1r7apek/ms6czezU4HXAjcDuPvPgZ/XnXYt8El3d2CfmY2a2Znu/nTK4xWRAK1WrySlUJptb6deNIMpJC1zLjAL/JWZXQQcAN7t7v9Wc844cLTm8bHKMQV3kR5rp3olLrUyXgnUzQK3etEMnpDgvgK4BLjF3feb2V3AJPCHNedYxM813Jcxs82U0zasWrWq9dGKSFPNqleiZvVJbX4VuLMpJOd+DDjm7vsrj++jHOzrz1lZ8/hs4Hj9C7n7DnefcPeJsbGxdsYrIk0kVa9UZ/Uzc/M4y2f12oA6X5rO3N39X8zsqJmtcffDwFXAt+tO2w28y8w+C1wOPKd8u0h/JFWvJM3q906uVzDPkdBqmVuAT5vZo8DFwH83sy1mtqXy/APAE8AR4OPAO1IfqYgESapeUU16cQTVubv7NDBRd/jumucdeGeK4xIpvHb7tSRVr2x/8LBq0gtC7QdEBlCn/VriboL2Y39U6Q+1HxAZQEm58U6025pAskczd5EB1E5uPDSNo9LGYtDMXWQAxeXA447vOjjD1vseWVbiuPW+R9h1cKaLo5RBpuAuMoBa7dfyR1/8FguLy9cNLiw6f/TFbzWcW+3+eM7k/azbtkcfADmltIzIAGq1X8uzJxaCjmtjjeJQcBfpkVZLG7uRG9fGGsWh4C7SA92eMY+OlJibb5y9j46Ulj3WIqbiUM5dpAe6VdpY9YGNF1AaWt6/rzRkfGDjBcuOtXqjVrJLwV2kQyE3KLs9Y960dpztb75oWf369jdf1PCvAm2sURxKy4h0IDTd0out6EJy9NpYozis3Bam9yYmJnxqaqov7y2SlnXb9sRucrF3cv3S46g9SkdKw3zwTRcCCrYSzswOuHt9r68GmrmLdCA03RI3YwZUmihdoeAu0oFW0i1RaZN12/aoNFG6QjdURTrQ6Q3KuJn/zNy8Vo9KRxTcRTrQaZfFpBuqM3PzbL1X/WGkPbqhKtIjUStUAbbe90hDX5haoyMlpt//+uDXVDon33RDVWSAxJVMXnfpODSZX0WtPE16TdDNWFFwF2lLqzPmuBWq9+w/ymKb/3pWnxhJouAu0qJ2ZsxxN05DAvvpp5Qij6tPjCRRcBdJEDVDb2fGHFcyOWyWGOBLw8b7f+OCyOd6sepVskvVMiIxqjP02t2Nqo+jJM2Y40omb7x8ZcPxavuv8dERtl/f2B+m2WuqT4yAZu4iseJm6HGz7aQZc1JPl4lX/kJbFS/qEyNJgkohzexJ4MfAIvB8fRmOmb0O+Dvgu5VDn3f3O5JeU6WQMujOmbw/tpBlpDQc2SdGgVW6rRulkFe6+w8Snv+Gu1/TwuuJDLS4nPZ4Te5dM2YZVErLiMTYumFNZCfHaiBXMJdBFnpD1YGvmNkBM9scc85rzOwRM/uSmUXf3hfJkE5bC4j0U2jO/Sx3P25mrwC+Ctzi7l+vef5U4KS7/8TMrgbucvfzIl5nM7AZYNWqVZc+9dRTaV2HiEghhObcg2bu7n688uczwBeAy+qe/5G7/6Ty/QNAyczOiHidHe4+4e4TY2NjIW8tIiJtaJpzN7OXAkPu/uPK968H7qg755eA77u7m9lllD80ftiNAYvUimsDoIZaUnRN0zJmdi7l2TqUPww+4+5/YmZbANz9bjN7F/B24HlgHniPu/9D0uuqFFI6Fbd13XWXjvO5AzPLjhvlG0fjCvSScaFpGbX8lcyK27+02ZJ+1aRLlqWacxcZRO0246r2gRHJMwV3yay45f7DZpHHa6lzouSdgrtkVivNuOqpc6LknVaoSmaFNOOK6+C4+uUK7pJvuqEqufYfbn8gMgc/bMZ3Pnh1H0Yk0hntoSoDK80a9GavFXdztd2t7USyQsFdeirNTZ1DXiuuLHLYTAugJNd0Q1V6KmmLum681o2Xr4z82SvOPT1yl6X37joUeXzXwZmWxyfSTwru0lNpbuoc8lp3brqQm65YtVQeOWzGTVes4skfzkd+MNyz/2hqHz4i/aS0jPRU0qbOIemQ2nOGAre7u3PThdy56cJlx86ZvD9yfHG5eNXFS9Zo5i49FVebfuX5Y03TIfUbVkcF4tANoltdAKW6eMkaBXfpqbgNMB56fLZpOiQqxw7lgNzqZhqtLIAK/cAQGSRKy0jPRW1Rd9vO6chza9MhcamRk+58d9sbWx4DJC+AUrWMZJmCuwyEpFx8K+e0Im4fVO2PKnmgtIz01a6DM0ute+uz3fXpkLhUilImIo00c5e+qV+E5CRvqpGUShGR5RTcpW+ibpBWA/veyfWRP6OUiUgYpWWkb9Jc0CQiyym4S9/E3QhVTblI55SWkZ6IWn26dcOayA2udYNUpHOauUvX1a8sre3eGLWgSTl1kc5p5i5dF9e98dad05FVMSLSOQV3SVVU+iXpBmkn/dxFJF5QWsbMnjSzQ2Y2bWYNe+NZ2UfM7IiZPWpml6Q/VBl0cemX0VNKiT+nlroi6Wtl5n6lu/8g5rk3AOdVvi4HPlb5UwokLv3y4hVDjJSGI5t+Van8USRdad1QvRb4pJftA0bN7MyUXlsyIi5APze/sHTjNI7KH0XSFRrcHfiKmR0ws80Rz48DR2seH6sckwJJqlvftHacvZPr+fBbLlZ/GJEeCE3LrHP342b2CuCrZva4u3+95vmoHQ4adlKofDBsBli1alXLg5X0dGMT6JC6dfWHEemNoODu7scrfz5jZl8ALgNqg/sxoHYn4rOB4xGvswPYATAxMRG9n5l0TTWgVzswVn8BaVWshAZu9YcR6b6mwd3MXgoMufuPK9+/Hrij7rTdwLvM7LOUb6Q+5+5Ppz5aaVtUB8Za1YqVToOuArfIYAiZuf8i8AUr7y25AviMu3/ZzLYAuPvdwAPA1cAR4ATw290ZrrQrbou6WqpYEcmPpsHd3Z8ALoo4fnfN9w68M92hSZpCAnezipWQPH03cvki0jqtUC2IuC3qqppVrNSndaLy9CHniEhvqHFYQURtUVctcQpp2BW3QKl2ZWnIOSLSG5q5F0SnJYghG2to8w2RwaHgXiCdVLKcNlJibn4h8nhVXOpHq09Fek9pGQliUcvU6o5HpX60+lSkPzRzlyBzJxpn7fXHtfpUZHAouEuQ0JSLFjGJDAalZYRdB2dYt20P50zez7pte9h1cKbhHKVcRLJFM/eCC61NV8pFJFsU3AsuqTZdDb9EskvBvUBa2d9Uteki2abgXhBx6ZfRU0o8G1EJo9p0kWzTDdWCiEu/uKMbpSI5pOBeECH7mxphfWZEZPApLVMQSXXqulEqkj+auRfEleePtXRcRLJNwb0gHnp8tqXjIpJtSstkWCu7HqnkUaRYNHPPqGpp48zcPM4LpY1RrQMgvrRRJY8i+aTgngFRvV9a3fVIvWFEikVpmQEXt/ioPrBXxaVZ1BtGpFgU3Adc3Ax92IxF94bzk9IsKnkUKQ4F9z4KuSEaNxNfdGekNLws8CvNIiJVyrn3SegN0biZeHUlqVaWikiU4Jm7mQ0DU8CMu19T99zNwHagGpk+6u6fSGuQeRTaanfrhjUNOfbqDF1pFhGJ00pa5t3AY8CpMc/vdPd3dT6kYgitO9eNUBFpR1BwN7OzgTcCfwK8p6sjKojQPUlBN0JFpHWhOfcPA78PnEw45zoze9TM7jOzlVEnmNlmM5sys6nZ2WIve0+j7jxk71MRKaamwd3MrgGecfcDCad9EVjt7v8J+BrwN1EnufsOd59w94mxsWI2rKoG5Nt2TgPOkJWPD5tx3aXhM/RWV6iKSLGEzNzXARvN7Engs8B6M/tU7Qnu/kN3/1nl4ceBS1MdZZf1agZcH5DnF05yslKqvujO5w7MBL93qytURaRYmgZ3d7/d3c9299XADcAed7+p9hwzO7Pm4UbKN14zoZcz4KiAXKuV4KxGYCKSpO1FTGZ2BzDl7ruB3zWzjcDzwL8CN6czvO4LLUlspQNj3PkhgXdmbp5zJu9v+h6t3JAVkeJpKbi7+8PAw5Xv31dz/Hbg9jQH1ishM+C4/i5A5AfAzNw8BlSbAzTbjLpe7b8g6t+jKqn+XUSk8CtUQ1rhhuS3a9M78EJgrz0/ajPqJElpmk1rx7VCVURiFb63zNYNa9h67yMsnHwhHJeGbNkMOGR23yyfDuXNqH/rilXcs/8oi+6YwciKIeYXTjZ8GDR7b1D9u4jEK/zMHQBLfhwyuw/Jp582UuJzB2aWujm6g2N86C0XM67NNEQkRYUP7tsfPMzC4vJ588KiL0uHhCw4ahaER0rDmBGb3tFmGiKSpsIH95CUS1J+u1ojX72JWqv6uHr+XMzN1ONz88qhi0iqCp9zDy0pjMpv11fROCxVyYxHlDJWK2ni3ks5dBFJS+Fn7p2kQ6JuolYD+97J9Q2BWqkXEemVws/cO2mp2+oqUbXvFZFeKXxwh/bTIe2sElXqRUR6ofBpmU4ozSIig6pQM/dW+8M0ozSLiAyqwgT30P4w7911aGkF6bAZN16+kjs3XRj7ukqziMggKkxaJqQ/zHt3HeJT+763tIJ00Z1P7fse7911qKdjFRHpVGGCe0hlyz37j0aeE3dcRGRQZTYt02r+PKSypTpjrxd3XERkUGVy5t7O7kkhlS3DVt9AIPm4iMigymRwb2f/0JDeLTdevjLyZ+OOi4gMqkymZeLy5zNz86zbtic2RdOssqVaFdNKtYyIyCDKZHCPy59D8vZ0IXn6OzddqGAuIpmXybRMVP681vzCIrfunGbdtj1Lefh28vQiIlmVyZl77crQuBk8LJ/FJ+XptQhJRPImkzN3KAf4vZPrY7enq6oG8FY7OIqIZFlmg3tVsxQNsJRjj6I9SkUkj4KDu5kNm9lBM/v7iOdebGY7zeyIme03s9VpDjJJbYljnLNGR7jy/LHI5+KOi4hkWSsz93cDj8U89zbgWXf/j8CHgP/R6cBaUU3RfPgtF8cuVHro8dnIn407LiKSZUHB3czOBt4IfCLmlGuBv6l8fx9wlVnvl3UmLVRSzl1EiiS0WubDwO8DL4t5fhw4CuDuz5vZc8DLgR90PMIWxS1UamfXJBGRrGo6czeza4Bn3P1A0mkRxxq6bZnZZjObMrOp2dnepkO0a5KIFElIWmYdsNHMngQ+C6w3s0/VnXMMWAlgZiuA04B/rX8hd9/h7hPuPjE21tsbmSG9ZURE8sK8hXa2ZvY64Pfc/Zq64+8ELnT3LWZ2A/Amd//NpNeamJjwqampNoYsIlJcZnbA3Seandf2ClUzuwOYcvfdwF8A/8fMjlCesd/Q7uuKiEjnWgru7v4w8HDl+/fVHP8p8OY0ByYiIu3L/ApVERFppOAuIpJDCu4iIjmk4C4ikkMtlUKm+sZms8BTKbzUGfRhJewAKOJ1F/GaQdddJCHX/Ep3b7pQqG/BPS1mNhVS85k3RbzuIl4z6Lr7PY5eSvOalZYREckhBXcRkRzKQ3Df0e8B9EkRr7uI1wy67iJJ7Zozn3MXEZFGeZi5i4hIncwEdzP7dTM7XNmndTLi+b7t49otAdf8HjP7tpk9amb/18xe2Y9xpq3Zddecd72ZuZnloqIi5LrN7Dcrv/Nvmdlnej3GtAX8HV9lZg9V9m9+1Myu7sc402Rmf2lmz5jZP8U8b2b2kcp/k0fN7JK23sjdB/4LGAa+A5wLvAh4BHhV3TnvAO6ufH8DsLPf4+7BNV8JnFL5/u1Zv+bQ666c9zLg68A+YKLf4+7R7/s84CBweuXxK/o97h5c8w7g7ZXvXwU82e9xp3DdrwUuAf4p5vmrgS9R3gTpCmB/O++TlZn7ZcARd3/C3X9OedOQa+vOGYh9XFPU9Jrd/SF3P1F5uA84u8dj7IaQ3zXAHwP/E/hpLwfXRSHX/d+AP3f3ZwHc/ZkejzFtIdfswKmV708DjvdwfF3h7l8nYjOjGtcCn/SyfcComZ3Z6vtkJbgv7dFacaxyLPIcd38eqO7jmlUh11zrbZQ/7bOu6XWb2Vpgpbv/fS8H1mUhv+9fBn7ZzPaa2T4z+/Weja47Qq75A8BNZnYMeAC4pTdD66tW/9+P1PZmHT0Wskdr0D6uGRJ8PWZ2EzAB/Oeujqg3Eq/bzIaADwE392pAPRLy+15BOTXzOsr/SvuGmb3a3ee6PLZuCbnmG4G/dvc/NbPXUN4U6NXufrL7w+ubVGJZVmbuS3u0VpxN4z/PgvZxzZCQa8bM/gvwB8BGd/9Zj8bWTc2u+2XAq4GHK/v6XgHszsFN1dC/43/n7gvu/l3gMOVgn1Uh1/w24G8B3P0fgZdQ7r+SZ0H/7zeTleD+/4HzzOwcM3sR5Rumu+vO2Q3818r31wN7vHJ3IqOaXnMlPfG/KQf2rOdfqxKv292fc/cz3H21u6+mfK9ho7tnfUPekL/juyjfRMfMzqCcpnmip6NMV8g1fw+4CsDMfoVycJ/t6Sh7bzfw1krVzBXAc+7+dMuv0u87xy3cYb4a+GfKd9f/oHLsDsr/Y0P5l34vcAT4f8C5/R5zD675a8D3genK1+5+j7kX11137sPkoFom8PdtwP8Cvg0cAm7o95h7cM2vAvZSrqSZBl7f7zGncM33AE8DC5Rn6W8DtgBban7Pf175b3Ko3b/fWqEqIpJDWUnLiIhICxTcRURySMFdRCSHFNxFRHJIwV1EJIcU3EVEckjBXUQkhxTcRURy6N8B/VrRMaud3fMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb560c8c9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 来看看产生的x-y分布\n",
    "test_x, test_y = generate_dataset()\n",
    "plt.scatter(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LR, self).__init__()\n",
    "        self.fc = nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "model = LR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确定损失函数和优化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define critereon - loss function\n",
    "critereon = nn.MSELoss()\n",
    "# define optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始进行优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 : Loss 1.2313394108787179e-05\n",
      "Epoch 9 : Loss 0.001408836804330349\n",
      "Epoch 14 : Loss 0.0030088736675679684\n",
      "Epoch 19 : Loss 0.004053980112075806\n",
      "Epoch 24 : Loss 0.00464647589251399\n",
      "Epoch 29 : Loss 0.004963480867445469\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = generate_dataset(100)\n",
    "nb_epochs = 30\n",
    "for epoch in range(nb_epochs):\n",
    "    epoch_loss = 0\n",
    "    for ix, x in enumerate(inputs):\n",
    "        # here x is the input. i.e. the input value of x\n",
    "        # and y_train[ix] is the output. i.e. y = f(x) = 3x + 4\n",
    "        y_pred = model(t.Tensor(x))\n",
    "        \n",
    "        loss = critereon(y_pred, t.Tensor(labels[ix]))\n",
    "        \n",
    "        epoch_loss = loss.data.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 5 == 4:\n",
    "        print(\"Epoch {} : Loss {}\".format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简要测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb560a17cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#x_test, y_test = get_fake_data(batch_size=40)\n",
    "label_pred = model(t.Tensor(inputs))\n",
    "plt.scatter(inputs, labels) # predicted\n",
    "\n",
    "plt.plot(inputs, label_pred.detach().numpy(), 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. torchtext、文本分类案例介绍    \n",
    "基于上述的理论与实践知识，我们可以开始建设实际的文本分类模型了，我们会基于`Toxic Comment Classification`这个例子进行介绍    \n",
    "由于实际工程任务中，预处理相关操作较为繁琐，在这里我也会同步介绍一个用于文本预处理的torchtext包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Toxic Comment Classification`： “有毒”评论分类   \n",
    "数据选取了Wikipedia’s talk page edits下的评论，分别被标注了toxic、severe_toxic、obscene、threat、insult以及identity_hate这6类标签，目的是建立模型以判断某条评论是否出现以上行为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/torchtext_routine.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 查看数据基本情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv  train.csv  valid.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = pd.read_csv(\"data/train.csv\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp['comment_text'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 声明 Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何对文本数据进行预处理并转换为数字，是利用Field实现的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data import Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们想把comment_text转化为小写，并按空格进行token化，所以如下选择Field参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda x: x.split()\n",
    "TEXT = Field(sequential=True, tokenize=tokenize, lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于此数据集中标签已进行基础处理，所以对标签的处理就更为简单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 生成数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于数据源是csv格式的，我们使用TabularDataset读取数据 (目前TabularDataset可以处理csv, tsv, 以及json文件)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于训练、验证数据，我们需要处理标签，传入参数的顺序必须与数据集中的顺序一直（不需要的数据可以传个None）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.23 ms, sys: 0 ns, total: 3.23 ms\n",
      "Wall time: 5.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tv_datafields = [(\"id\", None), \n",
    "                 (\"comment_text\", TEXT), (\"toxic\", LABEL),\n",
    "                 (\"severe_toxic\", LABEL), (\"threat\", LABEL),\n",
    "                 (\"obscene\", LABEL), (\"insult\", LABEL),\n",
    "                 (\"identity_hate\", LABEL)]\n",
    "\n",
    "trn, vld = TabularDataset.splits(\n",
    "        path=\"data\", # 数据都在data文件夹下\n",
    "        train='train.csv', validation=\"valid.csv\",\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=tv_datafields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集中没有任何的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.83 ms, sys: 0 ns, total: 1.83 ms\n",
      "Wall time: 9.16 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tst_datafields = [(\"id\", None), \n",
    "                 (\"comment_text\", TEXT)\n",
    "]\n",
    "\n",
    "tst = TabularDataset(\n",
    "        path=\"data/test.csv\", # the file path\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=tst_datafields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding(词嵌入，用一个低维向量表示词) 之类的后续处理，需要先将文本转化为数字，因此我们需要基于文本构建词库，构建方法如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.08 ms, sys: 0 ns, total: 2.08 ms\n",
      "Wall time: 2.08 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TEXT.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "词库如下， vocab.freqs是一个collections.Counter对象，所以我们可以看一下最常出现的几个词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 78),\n",
       " ('to', 41),\n",
       " ('you', 33),\n",
       " ('of', 30),\n",
       " ('and', 26),\n",
       " ('a', 26),\n",
       " ('is', 24),\n",
       " ('that', 22),\n",
       " ('i', 20),\n",
       " ('if', 19)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们稍微看一下数据集被转换成什么样子，数据集可以像list一样使用索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explanation', 'why', 'the']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0].comment_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 创建迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对train和valid数据集，我们使用一种特殊的iterator，叫**BucketIterator**    \n",
    "当我们使用神经网络进行训练时，每一个batch的长度应该是一样的，长度不足的会补0，过长的会切断   \n",
    "e.g.\n",
    "\\[ \n",
    "\\[3, 15, 2, 7\\],\n",
    "\\[4, 1\\], \n",
    "\\[5, 5, 6, 8, 1\\] \n",
    "\\] -> \\[ \n",
    "\\[3, 15, 2, 7, **0**\\],\n",
    "\\[4, 1, **0**, **0**, **0**\\], \n",
    "\\[5, 5, 6, 8, 1\\] \n",
    "\\]    \n",
    "如果数据长度相差太多，处理过程就会比较费时    \n",
    "BucketIterator会将相似长度的数据放到一起处理，降低耗时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "train_iter, val_iter = BucketIterator.splits(\n",
    "        (trn, vld), # we pass in the datasets we want the iterator to draw data from\n",
    "        batch_sizes=(64, 64),\n",
    "        device=-1, # if you want to use the GPU, specify the GPU number here\n",
    "        sort_key=lambda x: len(x.comment_text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "        sort_within_batch=False,\n",
    "        repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test部分不需要重排序，所以使用标准的Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "test_iter = Iterator(tst, batch_size=64, device=-1, sort=False, sort_within_batch=False, repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 封装迭代器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了便于使用，我们将把batch转换为形式为（x，y）的元组，其中x是自变量（模型的输入），y是因变量（标签数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_vars):\n",
    "        self.dl, self.x_var, self.y_vars = dl, x_var, y_vars # we pass in the list of attributes for x and y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            \n",
    "            if self.y_vars is not None: # we will concatenate y into a single tensor\n",
    "                y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y_vars], dim=1).float()\n",
    "            else:\n",
    "                y = torch.zeros((1))\n",
    "\n",
    "            yield (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用上面这个类来封装BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BatchWrapper(train_iter, \"comment_text\", [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\n",
    "valid_dl = BatchWrapper(val_iter, \"comment_text\", [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\n",
    "test_dl = BatchWrapper(test_iter, \"comment_text\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面就是每一组我们实际用来训练的数据、标签在经过上述预处理后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 15,  55,  15,  ...,  63, 375,  15],\n",
       "         [ 46, 531,   2,  ...,   4,  27, 144],\n",
       "         [ 10,   3, 645,  ..., 664, 526,   3],\n",
       "         ...,\n",
       "         [  1,   1,   1,  ...,   1,   1,   1],\n",
       "         [  1,   1,   1,  ...,   1,   1,   1],\n",
       "         [  1,   1,   1,  ...,   1,   1,   1]]),\n",
       " tensor([[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 建立并训练文本分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处利用我们上面提到的LSTM建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.LSTM的使用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq_len: timestep的数量        \n",
    "#batch_size: batch的大小       \n",
    "#input_size: 有多少个变量       \n",
    "#hidden_size: 隐藏单元个数      \n",
    "#number_layers: 层数      \n",
    "\n",
    "    \n",
    "#input = t.rand(seq_len, batch_size, input_size)       \n",
    "#lstm = nn.LSTM(input_size, hidden_size, number_layers)\n",
    "#h0 = t.randn(number_layers, batch_size, hidden_size)\n",
    "#c0 = t.randn(number_layers, batch_size, hidden_size)\n",
    "#out, hn = lstm(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBiLSTMBaseline(nn.Module):\n",
    "    def __init__(self, hidden_dim, emb_dim=300, recurrent_dropout=0.1, num_linear=1):\n",
    "        super().__init__() # don't forget to call this!\n",
    "        self.embedding = nn.Embedding(len(TEXT.vocab), emb_dim)\n",
    "        self.encoder = nn.LSTM(emb_dim, hidden_dim, num_layers=1, dropout=recurrent_dropout)\n",
    "        self.linear_layers = []\n",
    "        for _ in range(num_linear - 1):\n",
    "            self.linear_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        # 含可优化参数的层，需要使用nn.ModuleList, 这样其中可优化参数才能存到构造函数中的正确位置\n",
    "        self.linear_layers = nn.ModuleList(self.linear_layers)\n",
    "        self.predictor = nn.Linear(hidden_dim, 6)\n",
    "    \n",
    "    def forward(self, seq):\n",
    "        hdn, _ = self.encoder(self.embedding(seq))\n",
    "        feature = hdn[-1, :, :]\n",
    "        for layer in self.linear_layers:\n",
    "            feature = layer(feature)\n",
    "        preds = self.predictor(feature)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azurite/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleBiLSTMBaseline(\n",
       "  (embedding): Embedding(784, 100)\n",
       "  (encoder): LSTM(100, 500, dropout=0.1)\n",
       "  (linear_layers): ModuleList()\n",
       "  (predictor): Linear(in_features=500, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_sz = 100\n",
    "nh = 500\n",
    "nl = 3\n",
    "model = SimpleBiLSTMBaseline(nh, emb_dim=em_sz); model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using a GPU, remember to call model.cuda() to move your model to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.33s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 3.6392, Validation Loss: 1.9101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.87s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 3.1103, Validation Loss: 2.0560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.43s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 3.4557, Validation Loss: 1.8737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.28s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 2.9264, Validation Loss: 1.9535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.79s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training Loss: 2.9963, Validation Loss: 2.0557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.00s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Training Loss: 3.0620, Validation Loss: 2.1251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.26s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Training Loss: 3.0596, Validation Loss: 2.1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:13<00:00, 13.16s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Training Loss: 3.0028, Validation Loss: 2.1407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.04s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Training Loss: 2.9146, Validation Loss: 2.1359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: 2.8748, Validation Loss: 2.1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Training Loss: 2.9285, Validation Loss: 2.1937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.67s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Training Loss: 2.9692, Validation Loss: 2.1958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.74s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Training Loss: 2.9182, Validation Loss: 2.2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.99s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Training Loss: 2.8668, Validation Loss: 2.2309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.75s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Training Loss: 2.8795, Validation Loss: 2.2640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.08s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Training Loss: 2.9103, Validation Loss: 2.2802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.35s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Training Loss: 2.9169, Validation Loss: 2.2797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.67s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Training Loss: 2.8978, Validation Loss: 2.2741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.48s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Training Loss: 2.8713, Validation Loss: 2.2765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1/1 [00:04<00:00,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Training Loss: 2.8613, Validation Loss: 2.2910\n",
      "CPU times: user 8min 52s, sys: 14.5 s, total: 9min 6s\n",
      "Wall time: 2min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() # turn on training mode\n",
    "    for x, y in tqdm.tqdm(train_dl): # thanks to our wrapper, we can intuitively iterate over our data!\n",
    "        opt.zero_grad()\n",
    "        #x = x.cuda()\n",
    "        #y = y.cuda()\n",
    "        preds = model(x)\n",
    "        loss = loss_func(preds, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        running_loss += loss.data.item() * x.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(trn)\n",
    "    \n",
    "    # calculate the validation loss for this epoch\n",
    "    val_loss = 0.0\n",
    "    model.eval() # turn on evaluation mode\n",
    "    for x, y in valid_dl:\n",
    "        #x = x.cuda()\n",
    "        #y = y.cuda()\n",
    "        preds = model(x)\n",
    "        loss = loss_func(preds, y)\n",
    "        val_loss += loss.data.item() * x.size(0)\n",
    "\n",
    "    val_loss /= len(vld)\n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, epoch_loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.80it/s]\n"
     ]
    }
   ],
   "source": [
    "test_preds = []\n",
    "for x, y in tqdm.tqdm(test_dl):\n",
    "    #x = x.cuda()\n",
    "    #y = y.cuda()\n",
    "    preds = model(x)\n",
    "    # if you're data is on the GPU, you need to move the data back to the cpu\n",
    "    #preds = preds.data.cpu().numpy()\n",
    "    preds = preds.data.numpy()\n",
    "    # the actual outputs of the model are logits, so we need to pass these values to the sigmoid function\n",
    "    preds = 1 / (1 + np.exp(-preds))\n",
    "    test_preds.append(preds)\n",
    "test_preds = np.hstack(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/test.csv\")\n",
    "for i, col in enumerate([\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]):\n",
    "    df[col] = test_preds[:, i]\n",
    "\n",
    "# if you want to write the submission file to disk, uncomment and run the below code\n",
    "# df.drop(\"comment_text\", axis=1).to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>0.15087</td>\n",
       "      <td>0.044557</td>\n",
       "      <td>1.370166e-07</td>\n",
       "      <td>0.050182</td>\n",
       "      <td>0.03885</td>\n",
       "      <td>1.170060e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>0.15087</td>\n",
       "      <td>0.044557</td>\n",
       "      <td>1.370166e-07</td>\n",
       "      <td>0.050182</td>\n",
       "      <td>0.03885</td>\n",
       "      <td>1.170060e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>0.15087</td>\n",
       "      <td>0.044557</td>\n",
       "      <td>1.370166e-07</td>\n",
       "      <td>0.050182</td>\n",
       "      <td>0.03885</td>\n",
       "      <td>1.170060e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>0.15087</td>\n",
       "      <td>0.044557</td>\n",
       "      <td>1.370166e-07</td>\n",
       "      <td>0.050182</td>\n",
       "      <td>0.03885</td>\n",
       "      <td>1.170060e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>0.15087</td>\n",
       "      <td>0.044557</td>\n",
       "      <td>1.370166e-07</td>\n",
       "      <td>0.050182</td>\n",
       "      <td>0.03885</td>\n",
       "      <td>1.170060e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "     toxic  severe_toxic       obscene    threat   insult  identity_hate  \n",
       "0  0.15087      0.044557  1.370166e-07  0.050182  0.03885   1.170060e-07  \n",
       "1  0.15087      0.044557  1.370166e-07  0.050182  0.03885   1.170060e-07  \n",
       "2  0.15087      0.044557  1.370166e-07  0.050182  0.03885   1.170060e-07  \n",
       "3  0.15087      0.044557  1.370166e-07  0.050182  0.03885   1.170060e-07  \n",
       "4  0.15087      0.044557  1.370166e-07  0.050182  0.03885   1.170060e-07  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:   \n",
    "  * http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/\n",
    "  * http://colah.github.io/posts/2015-08-Understanding-LSTMs/   \n",
    "  * https://github.com/chenyuntc/pytorch-book   \n",
    "  * https://medium.com/@ally_20818/pytorch-101-linear-regression-with-pytorch-d2d22291c37d \n",
    "  * `Toxic Comment Classification`: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge        \n",
    "  * https://zhuanlan.zhihu.com/p/37223078    \n",
    "  * https://github.com/keitakurita/practical-torchtext"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
